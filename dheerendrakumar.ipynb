{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b709f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "                      ID        date     Item Id  \\\n",
      "0  2022-04-12_B09KDTS4DC  2022-04-12  B09KDTS4DC   \n",
      "1  2022-04-12_B09MR2MLZH  2022-04-12  B09MR2MLZH   \n",
      "2  2022-04-12_B09KSYL73R  2022-04-12  B09KSYL73R   \n",
      "3  2022-04-12_B09KT5HMNY  2022-04-12  B09KT5HMNY   \n",
      "4  2022-04-12_B09KTF8ZDQ  2022-04-12  B09KTF8ZDQ   \n",
      "\n",
      "                                           Item Name  ad_spend anarix_id  \\\n",
      "0  NapQueen Elizabeth 8\" Gel Memory Foam Mattress...       NaN  NAPQUEEN   \n",
      "1  NapQueen 12 Inch Bamboo Charcoal Queen Size Me...       NaN  NAPQUEEN   \n",
      "2     NapQueen Elsa 8\" Innerspring Mattress, Twin XL       NaN  NAPQUEEN   \n",
      "3        NapQueen Elsa 6\" Innerspring Mattress, Twin       NaN  NAPQUEEN   \n",
      "4     NapQueen Elsa 6\" Innerspring Mattress, Twin XL       NaN  NAPQUEEN   \n",
      "\n",
      "   units  unit_price  \n",
      "0    0.0         0.0  \n",
      "1    0.0         0.0  \n",
      "2    0.0         0.0  \n",
      "3    0.0         0.0  \n",
      "4    0.0         0.0  \n",
      "\n",
      "Test Data:\n",
      "                      ID        date     Item Id  \\\n",
      "0  2024-07-01_B09KDR64LT  2024-07-01  B09KDR64LT   \n",
      "1  2024-07-01_B09KDTS4DC  2024-07-01  B09KDTS4DC   \n",
      "2  2024-07-01_B09KDTHJ6V  2024-07-01  B09KDTHJ6V   \n",
      "3  2024-07-01_B09KDQ2BWY  2024-07-01  B09KDQ2BWY   \n",
      "4  2024-07-01_B09KDYY3SB  2024-07-01  B09KDYY3SB   \n",
      "\n",
      "                                           Item Name  ad_spend anarix_id  \\\n",
      "0  NapQueen Elizabeth 10\" Gel Memory Foam Mattres...       NaN  NAPQUEEN   \n",
      "1  NapQueen Elizabeth 8\" Gel Memory Foam Mattress...       NaN  NAPQUEEN   \n",
      "2  NapQueen Elizabeth 12\" Gel Memory Foam Mattres...       NaN  NAPQUEEN   \n",
      "3  NapQueen Elizabeth 12\" Gel Memory Foam Mattres...       NaN  NAPQUEEN   \n",
      "4  NapQueen Elizabeth 10\" Gel Memory Foam Mattres...    101.72  NAPQUEEN   \n",
      "\n",
      "   unit_price  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4      1094.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display the first few rows of the datasets\n",
    "print(\"Training Data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd77db",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d2e014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in training data:\n",
      "ID                0\n",
      "date              0\n",
      "Item Id           2\n",
      "Item Name      1832\n",
      "ad_spend      24187\n",
      "anarix_id         0\n",
      "units         17898\n",
      "unit_price        0\n",
      "dtype: int64\n",
      "\n",
      "Null values in test data:\n",
      "ID               0\n",
      "date             0\n",
      "Item Id          0\n",
      "Item Name      344\n",
      "ad_spend      1451\n",
      "anarix_id        0\n",
      "unit_price       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in training data\n",
    "print(\"Null values in training data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Check for null values in test data\n",
    "print(\"\\nNull values in test data:\")\n",
    "print(test_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366c22ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of training data:\n",
      "           ad_spend         units     unit_price\n",
      "count  77303.000000  83592.000000  101490.000000\n",
      "mean     110.771470     10.284381     106.750922\n",
      "std      529.303777     68.945915     425.704733\n",
      "min        0.000000   -173.000000   -8232.000000\n",
      "25%        0.000000      0.000000       0.000000\n",
      "50%        4.230000      1.000000       0.000000\n",
      "75%       44.310000      5.000000       0.000000\n",
      "max    47934.990000   9004.000000   21557.390000\n",
      "\n",
      "Summary statistics of test data:\n",
      "           ad_spend   unit_price\n",
      "count   1382.000000  2833.000000\n",
      "mean     198.838032    98.725873\n",
      "std      797.354508   383.585307\n",
      "min        0.000000 -1988.180000\n",
      "25%        0.730000     0.000000\n",
      "50%       39.200000     0.000000\n",
      "75%      156.012500     0.000000\n",
      "max    18724.850000  6870.000000\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics of training data\n",
    "print(\"Summary statistics of training data:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "# Summary statistics of test data\n",
    "print(\"\\nSummary statistics of test data:\")\n",
    "print(test_data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02c74d",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f44abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Impute missing ad_spend with median\n",
    "from sklearn.impute import SimpleImputer\n",
    "ad_spend_imputer = SimpleImputer(strategy='median')\n",
    "train_data['ad_spend'] = ad_spend_imputer.fit_transform(train_data[['ad_spend']])\n",
    "test_data['ad_spend'] = ad_spend_imputer.transform(test_data[['ad_spend']])\n",
    "\n",
    "# Impute missing units with 0\n",
    "units_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "train_data['units'] = units_imputer.fit_transform(train_data[['units']])\n",
    "\n",
    "# Drop rows with missing 'Item Id' and 'Item Name' in test data\n",
    "test_data.dropna(subset=['Item Id', 'Item Name'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b08dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "\n",
    "# Extract additional features\n",
    "test_data['day_of_week'] = test_data['date'].dt.dayofweek\n",
    "test_data['month'] = test_data['date'].dt.month\n",
    "test_data['day_of_year'] = test_data['date'].dt.dayofyear\n",
    "\n",
    "train_data['day_of_week'] = train_data['date'].dt.dayofweek\n",
    "train_data['month'] = train_data['date'].dt.month\n",
    "train_data['day_of_year'] = train_data['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96e4a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID       date     Item Id  \\\n",
      "0  2024-07-01_B09KDR64LT 2024-07-01  B09KDR64LT   \n",
      "1  2024-07-01_B09KDTS4DC 2024-07-01  B09KDTS4DC   \n",
      "2  2024-07-01_B09KDTHJ6V 2024-07-01  B09KDTHJ6V   \n",
      "3  2024-07-01_B09KDQ2BWY 2024-07-01  B09KDQ2BWY   \n",
      "4  2024-07-01_B09KDYY3SB 2024-07-01  B09KDYY3SB   \n",
      "\n",
      "                                           Item Name  ad_spend anarix_id  \\\n",
      "0  NapQueen Elizabeth 10\" Gel Memory Foam Mattres...      4.23  NAPQUEEN   \n",
      "1  NapQueen Elizabeth 8\" Gel Memory Foam Mattress...      4.23  NAPQUEEN   \n",
      "2  NapQueen Elizabeth 12\" Gel Memory Foam Mattres...      4.23  NAPQUEEN   \n",
      "3  NapQueen Elizabeth 12\" Gel Memory Foam Mattres...      4.23  NAPQUEEN   \n",
      "4  NapQueen Elizabeth 10\" Gel Memory Foam Mattres...    101.72  NAPQUEEN   \n",
      "\n",
      "   unit_price  day_of_week  month  day_of_year  \n",
      "0         0.0            0      7          183  \n",
      "1         0.0            0      7          183  \n",
      "2         0.0            0      7          183  \n",
      "3         0.0            0      7          183  \n",
      "4      1094.5            0      7          183  \n",
      "                      ID       date     Item Id  \\\n",
      "0  2022-04-12_B09KDTS4DC 2022-04-12  B09KDTS4DC   \n",
      "1  2022-04-12_B09MR2MLZH 2022-04-12  B09MR2MLZH   \n",
      "2  2022-04-12_B09KSYL73R 2022-04-12  B09KSYL73R   \n",
      "3  2022-04-12_B09KT5HMNY 2022-04-12  B09KT5HMNY   \n",
      "4  2022-04-12_B09KTF8ZDQ 2022-04-12  B09KTF8ZDQ   \n",
      "\n",
      "                                           Item Name  ad_spend anarix_id  \\\n",
      "0  NapQueen Elizabeth 8\" Gel Memory Foam Mattress...      4.23  NAPQUEEN   \n",
      "1  NapQueen 12 Inch Bamboo Charcoal Queen Size Me...      4.23  NAPQUEEN   \n",
      "2     NapQueen Elsa 8\" Innerspring Mattress, Twin XL      4.23  NAPQUEEN   \n",
      "3        NapQueen Elsa 6\" Innerspring Mattress, Twin      4.23  NAPQUEEN   \n",
      "4     NapQueen Elsa 6\" Innerspring Mattress, Twin XL      4.23  NAPQUEEN   \n",
      "\n",
      "   units  unit_price  day_of_week  month  day_of_year  \n",
      "0    0.0         0.0            1      4          102  \n",
      "1    0.0         0.0            1      4          102  \n",
      "2    0.0         0.0            1      4          102  \n",
      "3    0.0         0.0            1      4          102  \n",
      "4    0.0         0.0            1      4          102  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to check the new features\n",
    "print(test_data.head())\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60339715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing units in test data with 0\n",
    "test_data['units'] = test_data.get('units', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9141ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'date', 'Item Id', 'Item Name', 'ad_spend', 'anarix_id', 'units',\n",
      "       'unit_price', 'day_of_week', 'month', 'day_of_year', 'lag_1', 'lag_2',\n",
      "       'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(df, lag=7):\n",
    "    df = df.copy()\n",
    "    if 'units' in df.columns:\n",
    "        for i in range(1, lag + 1):\n",
    "            df[f'lag_{i}'] = df.groupby('Item Id')['units'].shift(i)\n",
    "    else:\n",
    "        print(\"The 'units' column is missing from the dataframe.\")\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "train_data = create_lag_features(train_data, lag=7)\n",
    "test_data = create_lag_features(test_data, lag=7)\n",
    "\n",
    "# Check the columns after creating lag features\n",
    "print(train_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8df3c5",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f74816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use available columns for features\n",
    "available_features = ['day_of_week', 'month', 'day_of_year', 'ad_spend']\n",
    "X = train_data[available_features]  # Feature matrix\n",
    "y = train_data['units']  # Target variable\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2e1bc",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34056fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best MSE: 2737.558994292369\n",
      "Validation MSE with best parameters: 1341.7745356133707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the model\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best MSE: {-grid_search.best_score_}\")\n",
    "\n",
    "# Train model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Validation MSE with best parameters: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf0a54",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afdd06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the submission file\n",
    "submission = test_data[['date', 'Item Id']].copy()\n",
    "submission['TARGET'] = test_data['units']\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4779269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
